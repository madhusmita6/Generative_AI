{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cdae945856b444d4800bccc31199e2b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21e1c4dcc7b940e78a0bea2208d17bdf",
              "IPY_MODEL_b654f5fb85b64830abb1db38965325f3",
              "IPY_MODEL_650d35f7494f48b5a697135f65ce4d39"
            ],
            "layout": "IPY_MODEL_fd1d9db94ebe4d52ac67a01944e3d5b5"
          }
        },
        "21e1c4dcc7b940e78a0bea2208d17bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_950b91c9f37c4496972674202fe44b4e",
            "placeholder": "​",
            "style": "IPY_MODEL_f7ba6a2e3573487b91dbd3503727dbc4",
            "value": "Map: 100%"
          }
        },
        "b654f5fb85b64830abb1db38965325f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fae6392ca7042d4ae8a66f6b1746a25",
            "max": 998,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8908b8b34ee49afb45e397be7488116",
            "value": 998
          }
        },
        "650d35f7494f48b5a697135f65ce4d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a20774d93b084842824a8739638d03ea",
            "placeholder": "​",
            "style": "IPY_MODEL_756340a91bf94fc99de71c16ce03d184",
            "value": " 998/998 [00:02&lt;00:00, 300.73 examples/s]"
          }
        },
        "fd1d9db94ebe4d52ac67a01944e3d5b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "950b91c9f37c4496972674202fe44b4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7ba6a2e3573487b91dbd3503727dbc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fae6392ca7042d4ae8a66f6b1746a25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8908b8b34ee49afb45e397be7488116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a20774d93b084842824a8739638d03ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "756340a91bf94fc99de71c16ce03d184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook will walk you through the process of instruction fine-tuning an LLM. The steps that we will take to perform this task are as follows:\n",
        "\n",
        "1. Installing and importing required libraries\n",
        "2. Comparing outputs from the two types of models\n",
        "3. Exploring the fine-tuning data set\n",
        "4. Data Preparation\n",
        "5. Training and inference\n",
        "\n",
        "## Problem Statement\n",
        "\n",
        "> Fine tune a large language model using a data set that contains question answer pairs from the context of customer care.\n",
        "\n",
        "## Data Description\n",
        "\n",
        "The data set contains the following columns:\n",
        "- flags: Contains tags for each entry in the data set\n",
        "- instruction: A user request from the Customer Service domain\n",
        "- category: The high-level semantic category for the intent\n",
        "- intent: The intent corresponding to the user instruction\n",
        "- response: An example expected response from the virtual assistant\n",
        "\n",
        "\n",
        "We will mainly be using the *instruction*, *category*, and *response* columns for fine tuning.\n"
      ],
      "metadata": {
        "id": "Suw-8fupw4HJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing and importing required libraries\n",
        "\n",
        "In this section, we will install and import the required libraries. Please make sure that you are using the T4 GPU runtime before installing the libraries."
      ],
      "metadata": {
        "id": "rch7k9POxJnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing required libraries\n",
        "! pip install --upgrade pip lamini --disable-pip-version-check torch transformers==4.31.0 datasets --quiet accelerate==0.20.3"
      ],
      "metadata": {
        "id": "m92p64HH4WDA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After installing the required libraries, we can now import the required methods from those libraries."
      ],
      "metadata": {
        "id": "fVkKE0fkx9EK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lamini\n",
        "from google.colab import userdata\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
        "import pandas as pd\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "bxKQsTpP48Fl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After importing required libraries, let's move on to comparing the outputs of instruction fine-tuned and non instruction fine-tuned models for the same input."
      ],
      "metadata": {
        "id": "q_dShEAF3Lc-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kFF6Zs05zC0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing outputs from the two types of models\n",
        "\n",
        "To load the model easily, we are going to use the API provided by Lamini. Their `LLMEngine()` and `BasicModelRunner()` methods provide a simple interface for quickly loading LLMs.\n",
        "\n",
        "Let's start by setting the API key for the Lamini API. Please make note of the use of the *secrets* functionality provided by Google Colab.\n"
      ],
      "metadata": {
        "id": "zsJ1yBmS3kMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lamini.api_key = \"da71c8a1fa4e4e37b7fcd22aef1720e9\"\n",
        "lamini.api_key = userdata.get('my_lamini_api_token')"
      ],
      "metadata": {
        "id": "bonuCDuX76Em"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlLHO9XiSU1N",
        "outputId": "901e13cc-63d2-45eb-e63f-80aecd82ef4e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lamini import Lamini\n"
      ],
      "metadata": {
        "id": "IMrER3hv03_j"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now prompt the base model (a model that has not been instruction fine-tuned), `Llama-2-7b-hf`."
      ],
      "metadata": {
        "id": "mxbxcgvqCWbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "non_chat_fine_tuned_model =lamini.Lamini(\"meta-llama/Llama-2-7b-hf\")\n",
        "print(non_chat_fine_tuned_model.generate(\"How to be a good data scientist?\"))"
      ],
      "metadata": {
        "id": "JzfG6qyt6pcV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6a6c8b2-f2f1-4e3f-9557-bd759b615eb2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "How to be a good data scientist? Data science is a field that is growing rapidly. It is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist.\n",
            "Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist.\n",
            "Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist.\n",
            "Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist.\n",
            "Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly changing and evolving. There are many different ways to be a good data scientist. In this article, we will discuss some of the ways that you can be a good data scientist. Data science is a field that is constantly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, we can also look at the output of the chat fine-tuned Llama 2 model."
      ],
      "metadata": {
        "id": "h7r8Y8UO7Ajx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_fine_tuned_model = lamini.Lamini(\"meta-llama/Llama-2-7b-chat-hf\")\n",
        "print(chat_fine_tuned_model.generate(\"How to be a good data scientist?\"))"
      ],
      "metadata": {
        "id": "HECWOaOQ3lj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "304e12da-012c-48aa-b971-2b0fb1178708"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Data science is a field that combines mathematics, statistics, computer science, and domain expertise in order to extract insights and knowledge from data. To be a good data scientist, one must have a strong foundation in these areas, as well as the ability to communicate complex ideas to non-technical stakeholders. Here are some key skills and traits that are important for data scientists to possess:\n",
            "\n",
            "1. Strong analytical and problem-solving skills: Data scientists must be able to analyze complex data sets and identify patterns, trends, and insights. They must also be able to communicate their findings effectively to stakeholders.\n",
            "2. Programming skills: Data scientists must be proficient in programming languages such as Python, R, or SQL, and be able to write efficient and well-structured code.\n",
            "3. Statistical knowledge: Data scientists must have a strong understanding of statistical concepts such as hypothesis testing, regression analysis, and time series analysis.\n",
            "4. Machine learning skills: Data scientists must be familiar with machine learning algorithms such as supervised and unsupervised learning, and be able to apply them to real-world data sets.\n",
            "5. Data visualization skills: Data scientists must be able to communicate complex data insights effectively through data visualization tools such as Tableau, Power BI, or D3.js.\n",
            "6. Domain expertise: Data scientists must have a deep understanding of the domain they are working in, and be able to apply their data analysis skills to solve real-world problems.\n",
            "7. Communication skills: Data scientists must be able to communicate complex technical concepts to non-technical stakeholders, and be able to present their findings in a clear and concise manner.\n",
            "8. Collaboration skills: Data scientists must be able to work effectively in a team environment, and be able to collaborate with stakeholders, data engineers, and other data scientists.\n",
            "9. Curiosity and creativity: Data scientists must be curious and creative in their approach to data analysis, and be able to think outside the box to identify new insights and opportunities.\n",
            "10. Ethical considerations: Data scientists must be aware of ethical considerations such as data privacy and security, and be able to apply these principles in their work.\n",
            "\n",
            "In addition to these skills and traits, data scientists must also be able to stay up-to-date with the latest trends and technologies in the field, and be able to adapt their skills and knowledge to new and emerging challenges.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can clearly see the difference between the outputs of the two models.\n",
        "\n",
        "Let's now move on to the fine tuning task. We will start by exploring the data set that we will use for fine-tuning.\n",
        "\n",
        "Let's do one more test to get the persepective of the difference between fine-tuned output and generic model output."
      ],
      "metadata": {
        "id": "bgav16yC4Zxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_fine_tuned_model.generate(\"i need help cancelling purchase {{Order Number}}\"))"
      ],
      "metadata": {
        "id": "1d-xyQiy1Mce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33ee0f70-f73d-42d2-dc6c-6964a33705ca"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "I apologize, but I'm a large language model, I don't have access to your personal information or financial accounts. Therefore, I cannot assist you in cancelling a purchase.\n",
            "\n",
            "If you need to cancel an order, you should contact the merchant or retailer directly. They will be able to assist you with the cancellation process and provide you with any necessary instructions.\n",
            "\n",
            "You can find the contact information for the merchant or retailer by checking your order confirmation email or by visiting their website. They will be able to provide you with the necessary information to cancel your order.\n",
            "\n",
            "Additionally, you can also contact your credit card issuer or bank for assistance with cancelling a purchase. They may be able to help you cancel the transaction or provide you with additional information on how to proceed.\n",
            "\n",
            "I hope this helps. Let me know if you have any other questions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring the fine-tuning data set\n",
        "\n",
        "In this section, we will download and explore the data set that we will use for fine-tuning."
      ],
      "metadata": {
        "id": "MbCVtLONRQmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"https://raw.githubusercontent.com/bitext/customer-support-llm-chatbot-training-dataset/main/data/Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv\""
      ],
      "metadata": {
        "id": "7ok9z6E_8LVu"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_q_a_MM = pd.read_csv(data_path)"
      ],
      "metadata": {
        "id": "Oj3iSobP8LYU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_q_a_MM"
      ],
      "metadata": {
        "id": "DThsz_v98Lbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "4f8fe8d1-7c46-4683-b600-773ee965e5a7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       flags                                        instruction category  \\\n",
              "0          B   question about cancelling order {{Order Number}}    ORDER   \n",
              "1        BQZ  i have a question about cancelling oorder {{Or...    ORDER   \n",
              "2       BLQZ    i need help cancelling puchase {{Order Number}}    ORDER   \n",
              "3         BL         I need to cancel purchase {{Order Number}}    ORDER   \n",
              "4      BCELN  I cannot afford this order, cancel purchase {{...    ORDER   \n",
              "...      ...                                                ...      ...   \n",
              "26867     BL  I am waiting for a rebate of {{Refund Amount}}...   REFUND   \n",
              "26868    BIL  how to see if there is anything wrong with my ...   REFUND   \n",
              "26869   BLQZ  I'm waiting for a reimbjrsement of {{Currency ...   REFUND   \n",
              "26870     BL  I don't know what to do to see my reimbursemen...   REFUND   \n",
              "26871     BL  I need to know if there is anything new on the...   REFUND   \n",
              "\n",
              "             intent                                           response  \n",
              "0      cancel_order  I've understood you have a question regarding ...  \n",
              "1      cancel_order  I've been informed that you have a question ab...  \n",
              "2      cancel_order  I can sense that you're seeking assistance wit...  \n",
              "3      cancel_order  I understood that you need assistance with can...  \n",
              "4      cancel_order  I'm sensitive to the fact that you're facing f...  \n",
              "...             ...                                                ...  \n",
              "26867  track_refund  Thank you for sharing your situation regarding...  \n",
              "26868  track_refund  Ensuring the accuracy of your restitution is o...  \n",
              "26869  track_refund  Firstly, I genuinely understand the importance...  \n",
              "26870  track_refund  I've understood you're unsure about how to che...  \n",
              "26871  track_refund  It's completely understandable that you want t...  \n",
              "\n",
              "[26872 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ffa79006-1bde-433e-a9af-00489fc02a60\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>flags</th>\n",
              "      <th>instruction</th>\n",
              "      <th>category</th>\n",
              "      <th>intent</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B</td>\n",
              "      <td>question about cancelling order {{Order Number}}</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I've understood you have a question regarding ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BQZ</td>\n",
              "      <td>i have a question about cancelling oorder {{Or...</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I've been informed that you have a question ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BLQZ</td>\n",
              "      <td>i need help cancelling puchase {{Order Number}}</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I can sense that you're seeking assistance wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BL</td>\n",
              "      <td>I need to cancel purchase {{Order Number}}</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I understood that you need assistance with can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BCELN</td>\n",
              "      <td>I cannot afford this order, cancel purchase {{...</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I'm sensitive to the fact that you're facing f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26867</th>\n",
              "      <td>BL</td>\n",
              "      <td>I am waiting for a rebate of {{Refund Amount}}...</td>\n",
              "      <td>REFUND</td>\n",
              "      <td>track_refund</td>\n",
              "      <td>Thank you for sharing your situation regarding...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26868</th>\n",
              "      <td>BIL</td>\n",
              "      <td>how to see if there is anything wrong with my ...</td>\n",
              "      <td>REFUND</td>\n",
              "      <td>track_refund</td>\n",
              "      <td>Ensuring the accuracy of your restitution is o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26869</th>\n",
              "      <td>BLQZ</td>\n",
              "      <td>I'm waiting for a reimbjrsement of {{Currency ...</td>\n",
              "      <td>REFUND</td>\n",
              "      <td>track_refund</td>\n",
              "      <td>Firstly, I genuinely understand the importance...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26870</th>\n",
              "      <td>BL</td>\n",
              "      <td>I don't know what to do to see my reimbursemen...</td>\n",
              "      <td>REFUND</td>\n",
              "      <td>track_refund</td>\n",
              "      <td>I've understood you're unsure about how to che...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26871</th>\n",
              "      <td>BL</td>\n",
              "      <td>I need to know if there is anything new on the...</td>\n",
              "      <td>REFUND</td>\n",
              "      <td>track_refund</td>\n",
              "      <td>It's completely understandable that you want t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26872 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ffa79006-1bde-433e-a9af-00489fc02a60')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ffa79006-1bde-433e-a9af-00489fc02a60 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ffa79006-1bde-433e-a9af-00489fc02a60');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b38ca8d7-6642-49f3-b115-33ddcd33d221\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b38ca8d7-6642-49f3-b115-33ddcd33d221')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b38ca8d7-6642-49f3-b115-33ddcd33d221 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bc0584f1-faf0-48b9-8de7-24a025a50daf\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_q_a_MM')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bc0584f1-faf0-48b9-8de7-24a025a50daf button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_q_a_MM');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_q_a_MM",
              "summary": "{\n  \"name\": \"df_q_a_MM\",\n  \"rows\": 26872,\n  \"fields\": [\n    {\n      \"column\": \"flags\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 394,\n        \"samples\": [\n          \"BCELNQ\",\n          \"BS\",\n          \"BCILNZ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24635,\n        \"samples\": [\n          \"I have an issue with the online registration\",\n          \"can you help me to open a standard account?\",\n          \"I want to locate order {{Order Number}}, could I get some help?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"REFUND\",\n          \"ORDER\",\n          \"DELIVERY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"contact_customer_service\",\n          \"delivery_period\",\n          \"contact_human_agent\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26870,\n        \"samples\": [\n          \"Thank you for reaching out! I'm sorry to hear that you're facing difficulties in connecting with a human agent. Please rest assured that I'm here to assist you and resolve this issue. Could you please provide me with some more details about the problem you're experiencing? This will help me find the best solution for you.\",\n          \"I'll get right on it! I understand your need to locate the bills associated with {{Person Name}}. To assist you in finding the relevant invoices, could you please provide me with some additional details such as the date range or any other specific information that might help narrow down the search? Rest assured, I'm here to guide you every step of the way and ensure a seamless experience.\",\n          \"Definitely! I'm here to provide you with the necessary assistance in reporting any payment problems you are facing. Please share the specific details of the issue you're encountering, such as the nature of the problem, any error messages you've received, and any relevant transaction or account information. This will help us investigate and address the problem effectively. We appreciate your cooperation in bringing this matter to our attention, and we're committed to working together to find a solution.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"question: \" + df_q_a_MM.iloc[1][\"instruction\"])\n",
        "print(\"answer: \" + df_q_a_MM.iloc[1][\"response\"])"
      ],
      "metadata": {
        "id": "QLnX10HUR63A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f38f5e-1b12-43ad-c6d0-9f1efc153794"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: i have a question about cancelling oorder {{Order Number}}\n",
            "answer: I've been informed that you have a question about canceling order {{Order Number}}. I'm here to assist you! Please go ahead and let me know what specific question you have, and I'll provide you with all the information and guidance you need. Your satisfaction is my top priority.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"question: \" + df_q_a_MM.iloc[2][\"instruction\"])\n",
        "print(\"answer: \" + df_q_a_MM.iloc[2][\"response\"])"
      ],
      "metadata": {
        "id": "ofLYmF4GR65h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdad1fd2-1ad8-4c89-aadf-88bd53cee7dd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: i need help cancelling puchase {{Order Number}}\n",
            "answer: I can sense that you're seeking assistance with canceling your purchase with the purchase number {{Order Number}}. I apologize for any inconvenience caused, and I'm here to guide you through the process.\n",
            "\n",
            "To cancel your purchase, please follow these steps:\n",
            "\n",
            "1. Log into your account: Visit our {{Online Company Portal Info}} and sign in using your credentials.\n",
            "2. Locate your order: Once logged in, navigate to the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section to find the purchase with the order number {{Order Number}}.\n",
            "3. Initiate the cancellation: Upon finding your purchase, look for the option labeled '{{Online Order Interaction}}' and click on it to initiate the cancellation process.\n",
            "4. Confirm the cancellation: Our system might ask for confirmation or feedback regarding the cancellation. Kindly provide the necessary information to complete the process.\n",
            "5. Seek additional support: If you encounter any difficulties or require further assistance, our dedicated customer support team is available during {{Customer Support Hours}}. You can contact us at {{Customer Support Phone Number}} or use the Live Chat feature on our {{Website URL}}.\n",
            "\n",
            "We appreciate your understanding and value your satisfaction. Should you have any more questions or concerns, feel free to reach out to us. We're here to help you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have now explored the data set. Next let's explore the process of preparing the data for training."
      ],
      "metadata": {
        "id": "DGgQztHb6Ez8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "X_l8ms8IkcgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model that we are going to use for fine-tuning is the pythia-70m model. It has 70 million parameters and it a fairly small model compared to other LLMs. LLMs come with their own tokenizers which is what we are loading here in the next code cell.\n"
      ],
      "metadata": {
        "id": "n0PX9r_A6v-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")"
      ],
      "metadata": {
        "id": "wMP2YYRkj8Ru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37e3a2b2-3cdd-4ba0-e7cf-b6ce36bf5e46"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizers created by the `Autotokenizer` object can be used to tokenize a single string or a sequence of strings. While training the model, it is likely that you want to tokenize all the strings that will be used for the training process. Whereas during inference, you might want to tokenize only a single string on which you are running the inference.\n",
        "\n",
        "To demonstrate how tokenization works, we will first tokenize a single string and then put a few strings together in a sequence and examine what the output looks like."
      ],
      "metadata": {
        "id": "xdlidtP57dj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string = df_q_a_MM[\"instruction\"][0]"
      ],
      "metadata": {
        "id": "t9zbX4s9Gh7e"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string"
      ],
      "metadata": {
        "id": "kYn7vX-aYSRs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "43178772-d1fa-4188-cf19-83c29aad8b43"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'question about cancelling order {{Order Number}}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_string = tokenizer(string)"
      ],
      "metadata": {
        "id": "tY_nUmB0Gp2t"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoded_string)"
      ],
      "metadata": {
        "id": "Ftn-rICHHIzY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57c394bd-9e6b-4f99-cbca-cf7f1fb3da4b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [19751, 670, 476, 68, 3485, 1340, 12033, 13921, 11057, 599], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see that `encoded_string` contains two keys: `input_ids` and `attention_mask`. The values associated with `input_ids` are the actual tokens which will be sent into the model. Whereas the value associated with `attention_mask` tell the model which tokens to focus on and which tokens to ignore. You will learn about the attention mask later.\n",
        "\n",
        "Now let's try to tokenize a list of strings as we might need to do for training our model on a large data set of strings."
      ],
      "metadata": {
        "id": "sCzuYVFLHLco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instructions = df_q_a_MM[\"instruction\"][0]\n",
        "responses = df_q_a_MM[\"response\"][0]\n",
        "concatenated = [instructions, responses]"
      ],
      "metadata": {
        "id": "Cbw6y9DKl_aC"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(concatenated)"
      ],
      "metadata": {
        "id": "1Y23y4Sg5rcg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9db2243-e883-4a51-b6a4-ba498ebd1788"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(concatenated)"
      ],
      "metadata": {
        "id": "b5-YEZSblU4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "233bb8cd-e20a-4976-d418-1bfaa3f8e61f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['question about cancelling order {{Order Number}}', \"I've understood you have a question regarding canceling order {{Order Number}}, and I'm here to provide you with the information you need. Please go ahead and ask your question, and I'll do my best to assist you.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text = tokenizer(concatenated)"
      ],
      "metadata": {
        "id": "VWODkKnHj8Ye"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoded_text)"
      ],
      "metadata": {
        "id": "Niz3MrGu5k69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58e61a9e-24ed-4087-bb3d-f6f42130c019"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[19751, 670, 476, 68, 3485, 1340, 12033, 13921, 11057, 599], [42, 1849, 7192, 368, 452, 247, 1953, 5001, 14002, 272, 1340, 12033, 13921, 11057, 8503, 285, 309, 1353, 1060, 281, 2085, 368, 342, 253, 1491, 368, 878, 15, 7764, 564, 6386, 285, 1642, 634, 1953, 13, 285, 309, 1833, 513, 619, 1682, 281, 10073, 368, 15]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see in this output that the values associated with `input_ids` and 'attention_mask` are lists of lists. The items in the first list are the tokens for the two strings that we tokenized and the items in the second list are their respective attention masks.\n",
        "\n",
        "The need for attention masks arises because even though the length of the tokens accepted in an LLM is fixed and the size of our inputs will vary. You can also see this in the two lists of tokens that we have created above. As the size of the input strings were different, the lists of tokens are also of different sizes.\n",
        "\n",
        "To handle this problem, we perform padding and truncation during tokenization to bring the token lists to the same size. Let's now move on to padding and truncation.\n",
        "\n"
      ],
      "metadata": {
        "id": "zl7scc-A8CXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Padding and truncation\n",
        "\n",
        "Padding is used to bring the length of the list of tokens up to a uniform length by adding some placeholder tokens (if the length of the list of tokens is smaller than the required length). If the length of the list of tokens is longer than the required length, then perform truncation to bring it down to the required length.\n",
        "\n",
        "Let's start by assigning the token to be used in padding as the end of sentence token."
      ],
      "metadata": {
        "id": "MB3kUmhzm24E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "n0M5Q_mFm-mT"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.pad_token)"
      ],
      "metadata": {
        "id": "x9xb_hBXnuCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eb0fea7-1472-4979-ba34-a4412a35e14a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By setting the value of padding to `True` we can increase the size of the shorter list of tokens up to the length of the longest token list."
      ],
      "metadata": {
        "id": "bF-DA1smnAwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_texts_longest = tokenizer(concatenated, padding=True)\n",
        "print(\"Using padding: \", encoded_texts_longest[\"input_ids\"])\n",
        "print(\"Attention mask for this piece of text: \", encoded_texts_longest[\"attention_mask\"])"
      ],
      "metadata": {
        "id": "u8c7fBb8j8an",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad1d3e6e-a552-4996-bebe-439ab058516b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using padding:  [[19751, 670, 476, 68, 3485, 1340, 12033, 13921, 11057, 599, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [42, 1849, 7192, 368, 452, 247, 1953, 5001, 14002, 272, 1340, 12033, 13921, 11057, 8503, 285, 309, 1353, 1060, 281, 2085, 368, 342, 253, 1491, 368, 878, 15, 7764, 564, 6386, 285, 1642, 634, 1953, 13, 285, 309, 1833, 513, 619, 1682, 281, 10073, 368, 15]]\n",
            "Attention mask for this piece of text:  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, you can see that both the lists in `input_ids` are of the same length. But the padding token has been appended to the end of the shorter token list. You can also see that in the `attention_mask`, the values corresponding to the tokens that are irrelevant have been set to 0. You can read more about attention masks below."
      ],
      "metadata": {
        "id": "gMk7YQbNnPUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attention mask**\n",
        "\n",
        "***TL;DR***\n",
        "An attention mask in transformer models helps the model focus on important parts of the data and ignore unimportant parts, like padding tokens. This makes sure the model processes sequences correctly by not paying attention to the padding, which is important for tasks like translating or generating text. It also helps the model work better and faster by focusing only on the necessary parts of the input.\n",
        "\n",
        "*****************************\n",
        "***Explanation***\n",
        "An attention mask is used in transformer models to allow selective focus on valid data points and to prevent the model from attending to irrelevant information. Here's why it's necessary:\n",
        "\n",
        "Handling Padding: Sequences are often padded to match the longest sequence's length before being fed into a transformer model because most neural network architectures expect inputs of consistent size. The attention mask indicates to the model which tokens are padding and should not be attended to.\n",
        "\n",
        "Preserving Sequence Length: In tasks like translation or text generation, input sequences can vary significantly in length. The attention mask ensures that the self-attention mechanism doesn't consider these padded areas, maintaining the actual sequence length.\n",
        "\n",
        "Improving Model Focus: During the self-attention phase, the model computes scores between all pairs of positions in the input sequence. The attention mask allows the model to focus only on relevant positions and ignore the rest, such as padded tokens or future tokens in tasks that require strict ordering (like causal language modeling).\n",
        "\n",
        "Facilitating Different Tasks: Some tasks may require the model to only pay attention to certain parts of the input while ignoring others. For instance, in question-answering, the model should focus more on the portion of the text containing the answer.\n",
        "\n",
        "Enhancing Model Efficiency: By ignoring unnecessary tokens, attention masks can reduce computational waste, making training and inference more efficient, especially for longer sequences.\n",
        "\n",
        "Maintaining Context in Sequences: In causal or unidirectional language models, attention masks prevent the model from seeing future tokens, thus maintaining the flow of information in one direction. This is essential for preserving the autoregressive property where each token is predicted based on preceding tokens only.\n",
        "\n",
        "In essence, attention masks are crucial for directing the transformer's attention mechanism to process sequences efficiently and effectively, respecting the context and structure of the input data."
      ],
      "metadata": {
        "id": "-hJqSVkJcUJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also set the value of the `padding` parameter to 'max_length'. This way, you can specify the length of each padded string using the `max_length` parameter."
      ],
      "metadata": {
        "id": "F0h1eEkjqg5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_texts_longest = tokenizer(concatenated, max_length = 30, padding='max_length')\n",
        "print(\"Using padding: \", encoded_texts_longest[\"input_ids\"])\n",
        "print(\"Attention mask for this piece of text: \", encoded_texts_longest[\"attention_mask\"])\n",
        "print(\"Length of the list of tokens:\", len(encoded_texts_longest[\"input_ids\"][0]))"
      ],
      "metadata": {
        "id": "f_rTQZVnqehp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48097f9a-8f2a-412d-931b-84c0de30e74a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using padding:  [[19751, 670, 476, 68, 3485, 1340, 12033, 13921, 11057, 599, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [42, 1849, 7192, 368, 452, 247, 1953, 5001, 14002, 272, 1340, 12033, 13921, 11057, 8503, 285, 309, 1353, 1060, 281, 2085, 368, 342, 253, 1491, 368, 878, 15, 7764, 564, 6386, 285, 1642, 634, 1953, 13, 285, 309, 1833, 513, 619, 1682, 281, 10073, 368, 15]]\n",
            "Attention mask for this piece of text:  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
            "Length of the list of tokens: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To reduce the length of the sequences, you can truncate them by setting the value of the `truncation` argument to `True`. This will truncate all the strings to the length specified by the `max_length` argument."
      ],
      "metadata": {
        "id": "GqjiTrQ5uPbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_texts_truncation = tokenizer(concatenated, max_length=3, truncation=True)\n",
        "print(\"Using truncation: \", encoded_texts_truncation)"
      ],
      "metadata": {
        "id": "W3oQX8dwj8c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e691a290-65de-43c3-e811-4b8f02ef603e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using truncation:  {'input_ids': [[19751, 670, 476], [42, 1849, 7192]], 'attention_mask': [[1, 1, 1], [1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default the tokenizer truncates from the right-hand side, but you can specify the direction from which to truncate by setting the value of the `truncation_side` attribute."
      ],
      "metadata": {
        "id": "qN0bOFXju1x0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.truncation_side = \"left\"\n",
        "encoded_texts_truncation_left = tokenizer(concatenated, max_length=3, truncation=True)\n",
        "print(\"Using left-side truncation: \", encoded_texts_truncation_left)"
      ],
      "metadata": {
        "id": "5LXW3Frdj8fj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "434cf229-cf02-4680-f2a0-e23c85db4dff"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using left-side truncation:  {'input_ids': [[13921, 11057, 599], [10073, 368, 15]], 'attention_mask': [[1, 1, 1], [1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can do a combination of both padding and truncation as required by the problem at hand."
      ],
      "metadata": {
        "id": "FUfT_7DHvJnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_texts_both = tokenizer(concatenated, max_length=15, truncation=True, padding=True)\n",
        "print(\"Using both padding and truncation: \", encoded_texts_both[\"input_ids\"])"
      ],
      "metadata": {
        "id": "_gyZR-yzj8hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f23358ae-ffbd-44bb-e17c-d235d8d7b0f3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using both padding and truncation:  [[19751, 670, 476, 68, 3485, 1340, 12033, 13921, 11057, 599, 0, 0, 0, 0, 0], [285, 1642, 634, 1953, 13, 285, 309, 1833, 513, 619, 1682, 281, 10073, 368, 15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have now seen how to pad and truncate strings while performing tokenization. To prepare the data set to be sent into the LLM, we need to use a prompt template and send our input-output pairs into that prompt template.\n",
        "\n",
        "Let's see how we can do that for one record."
      ],
      "metadata": {
        "id": "XDLPwSJD_hwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using prompt templates\n",
        "\n",
        "Before tokenizing our question answer pairs and using them for training, we need to wrap them in a prompt so that the model can understand the relationship between the two. We will do that here.\n",
        "\n",
        "From our data set, we will only use the instruction and response columns."
      ],
      "metadata": {
        "id": "uq4AgC93oFzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_q_a_MM"
      ],
      "metadata": {
        "id": "M_EGwjve_BSJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "9353a284-cab0-4b12-e9de-910d95d9d462"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       flags                                        instruction category  \\\n",
              "0          B   question about cancelling order {{Order Number}}    ORDER   \n",
              "1        BQZ  i have a question about cancelling oorder {{Or...    ORDER   \n",
              "2       BLQZ    i need help cancelling puchase {{Order Number}}    ORDER   \n",
              "3         BL         I need to cancel purchase {{Order Number}}    ORDER   \n",
              "4      BCELN  I cannot afford this order, cancel purchase {{...    ORDER   \n",
              "...      ...                                                ...      ...   \n",
              "26867     BL  I am waiting for a rebate of {{Refund Amount}}...   REFUND   \n",
              "26868    BIL  how to see if there is anything wrong with my ...   REFUND   \n",
              "26869   BLQZ  I'm waiting for a reimbjrsement of {{Currency ...   REFUND   \n",
              "26870     BL  I don't know what to do to see my reimbursemen...   REFUND   \n",
              "26871     BL  I need to know if there is anything new on the...   REFUND   \n",
              "\n",
              "             intent                                           response  \n",
              "0      cancel_order  I've understood you have a question regarding ...  \n",
              "1      cancel_order  I've been informed that you have a question ab...  \n",
              "2      cancel_order  I can sense that you're seeking assistance wit...  \n",
              "3      cancel_order  I understood that you need assistance with can...  \n",
              "4      cancel_order  I'm sensitive to the fact that you're facing f...  \n",
              "...             ...                                                ...  \n",
              "26867  track_refund  Thank you for sharing your situation regarding...  \n",
              "26868  track_refund  Ensuring the accuracy of your restitution is o...  \n",
              "26869  track_refund  Firstly, I genuinely understand the importance...  \n",
              "26870  track_refund  I've understood you're unsure about how to che...  \n",
              "26871  track_refund  It's completely understandable that you want t...  \n",
              "\n",
              "[26872 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b737a99-566c-477c-8231-fa8041234adc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>flags</th>\n",
              "      <th>instruction</th>\n",
              "      <th>category</th>\n",
              "      <th>intent</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B</td>\n",
              "      <td>question about cancelling order {{Order Number}}</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I've understood you have a question regarding ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BQZ</td>\n",
              "      <td>i have a question about cancelling oorder {{Or...</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I've been informed that you have a question ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BLQZ</td>\n",
              "      <td>i need help cancelling puchase {{Order Number}}</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I can sense that you're seeking assistance wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BL</td>\n",
              "      <td>I need to cancel purchase {{Order Number}}</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I understood that you need assistance with can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BCELN</td>\n",
              "      <td>I cannot afford this order, cancel purchase {{...</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I'm sensitive to the fact that you're facing f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26867</th>\n",
              "      <td>BL</td>\n",
              "      <td>I am waiting for a rebate of {{Refund Amount}}...</td>\n",
              "      <td>REFUND</td>\n",
              "      <td>track_refund</td>\n",
              "      <td>Thank you for sharing your situation regarding...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26868</th>\n",
              "      <td>BIL</td>\n",
              "      <td>how to see if there is anything wrong with my ...</td>\n",
              "      <td>REFUND</td>\n",
              "      <td>track_refund</td>\n",
              "      <td>Ensuring the accuracy of your restitution is o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26869</th>\n",
              "      <td>BLQZ</td>\n",
              "      <td>I'm waiting for a reimbjrsement of {{Currency ...</td>\n",
              "      <td>REFUND</td>\n",
              "      <td>track_refund</td>\n",
              "      <td>Firstly, I genuinely understand the importance...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26870</th>\n",
              "      <td>BL</td>\n",
              "      <td>I don't know what to do to see my reimbursemen...</td>\n",
              "      <td>REFUND</td>\n",
              "      <td>track_refund</td>\n",
              "      <td>I've understood you're unsure about how to che...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26871</th>\n",
              "      <td>BL</td>\n",
              "      <td>I need to know if there is anything new on the...</td>\n",
              "      <td>REFUND</td>\n",
              "      <td>track_refund</td>\n",
              "      <td>It's completely understandable that you want t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26872 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b737a99-566c-477c-8231-fa8041234adc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b737a99-566c-477c-8231-fa8041234adc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b737a99-566c-477c-8231-fa8041234adc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6b4962fc-f6f1-4d11-aeb9-d00840884484\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6b4962fc-f6f1-4d11-aeb9-d00840884484')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6b4962fc-f6f1-4d11-aeb9-d00840884484 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_86ee9f86-5b7e-48ee-9074-556c9ac05b8e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_q_a_MM')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_86ee9f86-5b7e-48ee-9074-556c9ac05b8e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_q_a_MM');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_q_a_MM",
              "summary": "{\n  \"name\": \"df_q_a_MM\",\n  \"rows\": 26872,\n  \"fields\": [\n    {\n      \"column\": \"flags\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 394,\n        \"samples\": [\n          \"BCELNQ\",\n          \"BS\",\n          \"BCILNZ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24635,\n        \"samples\": [\n          \"I have an issue with the online registration\",\n          \"can you help me to open a standard account?\",\n          \"I want to locate order {{Order Number}}, could I get some help?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"REFUND\",\n          \"ORDER\",\n          \"DELIVERY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"contact_customer_service\",\n          \"delivery_period\",\n          \"contact_human_agent\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26870,\n        \"samples\": [\n          \"Thank you for reaching out! I'm sorry to hear that you're facing difficulties in connecting with a human agent. Please rest assured that I'm here to assist you and resolve this issue. Could you please provide me with some more details about the problem you're experiencing? This will help me find the best solution for you.\",\n          \"I'll get right on it! I understand your need to locate the bills associated with {{Person Name}}. To assist you in finding the relevant invoices, could you please provide me with some additional details such as the date range or any other specific information that might help narrow down the search? Rest assured, I'm here to guide you every step of the way and ensure a seamless experience.\",\n          \"Definitely! I'm here to provide you with the necessary assistance in reporting any payment problems you are facing. Please share the specific details of the issue you're encountering, such as the nature of the problem, any error messages you've received, and any relevant transaction or account information. This will help us investigate and address the problem effectively. We appreciate your cooperation in bringing this matter to our attention, and we're committed to working together to find a solution.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will choose a subset of our data set. You should try training on the whole data set."
      ],
      "metadata": {
        "id": "PuIwHI1SAk9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_q_a_MM = df_q_a_MM.loc[df_q_a_MM[\"intent\"] == \"cancel_order\"]"
      ],
      "metadata": {
        "id": "WMvoe0CkwWSl"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_q_a_MM"
      ],
      "metadata": {
        "id": "R4StrbFuyo7l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "b9ccde98-9650-44e9-a9ae-96d93eaa4a1a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     flags                                        instruction category  \\\n",
              "0        B   question about cancelling order {{Order Number}}    ORDER   \n",
              "1      BQZ  i have a question about cancelling oorder {{Or...    ORDER   \n",
              "2     BLQZ    i need help cancelling puchase {{Order Number}}    ORDER   \n",
              "3       BL         I need to cancel purchase {{Order Number}}    ORDER   \n",
              "4    BCELN  I cannot afford this order, cancel purchase {{...    ORDER   \n",
              "..     ...                                                ...      ...   \n",
              "993     BL    I need help to cancel purchase {{Order Number}}    ORDER   \n",
              "994     BL    I want help to cancel purchase {{Order Number}}    ORDER   \n",
              "995    BIL           how to cancel purchase {{Order Number}}?    ORDER   \n",
              "996    BLZ   I want help cancellkng purchase {{Order Number}}    ORDER   \n",
              "997     BL  I want assistance cancelling purchase {{Order ...    ORDER   \n",
              "\n",
              "           intent                                           response  \n",
              "0    cancel_order  I've understood you have a question regarding ...  \n",
              "1    cancel_order  I've been informed that you have a question ab...  \n",
              "2    cancel_order  I can sense that you're seeking assistance wit...  \n",
              "3    cancel_order  I understood that you need assistance with can...  \n",
              "4    cancel_order  I'm sensitive to the fact that you're facing f...  \n",
              "..            ...                                                ...  \n",
              "993  cancel_order  I'm fully aware that you're seeking assistance...  \n",
              "994  cancel_order  You've come to the right place! I understand t...  \n",
              "995  cancel_order  I've decoded that you're looking for assistanc...  \n",
              "996  cancel_order  I realized that you're seeking assistance with...  \n",
              "997  cancel_order  I understand your need for assistance in cance...  \n",
              "\n",
              "[998 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb7950bb-7910-4d46-b890-0c34a28529df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>flags</th>\n",
              "      <th>instruction</th>\n",
              "      <th>category</th>\n",
              "      <th>intent</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B</td>\n",
              "      <td>question about cancelling order {{Order Number}}</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I've understood you have a question regarding ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BQZ</td>\n",
              "      <td>i have a question about cancelling oorder {{Or...</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I've been informed that you have a question ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BLQZ</td>\n",
              "      <td>i need help cancelling puchase {{Order Number}}</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I can sense that you're seeking assistance wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BL</td>\n",
              "      <td>I need to cancel purchase {{Order Number}}</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I understood that you need assistance with can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BCELN</td>\n",
              "      <td>I cannot afford this order, cancel purchase {{...</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I'm sensitive to the fact that you're facing f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>BL</td>\n",
              "      <td>I need help to cancel purchase {{Order Number}}</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I'm fully aware that you're seeking assistance...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>994</th>\n",
              "      <td>BL</td>\n",
              "      <td>I want help to cancel purchase {{Order Number}}</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>You've come to the right place! I understand t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>BIL</td>\n",
              "      <td>how to cancel purchase {{Order Number}}?</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I've decoded that you're looking for assistanc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>BLZ</td>\n",
              "      <td>I want help cancellkng purchase {{Order Number}}</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I realized that you're seeking assistance with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>BL</td>\n",
              "      <td>I want assistance cancelling purchase {{Order ...</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I understand your need for assistance in cance...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>998 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb7950bb-7910-4d46-b890-0c34a28529df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fb7950bb-7910-4d46-b890-0c34a28529df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fb7950bb-7910-4d46-b890-0c34a28529df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ce7604d5-22a0-42ab-bdc2-673026a2cade\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ce7604d5-22a0-42ab-bdc2-673026a2cade')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ce7604d5-22a0-42ab-bdc2-673026a2cade button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_451cebb3-a0d7-470d-8c52-5cc885235ccd\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_q_a_MM')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_451cebb3-a0d7-470d-8c52-5cc885235ccd button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_q_a_MM');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_q_a_MM",
              "summary": "{\n  \"name\": \"df_q_a_MM\",\n  \"rows\": 998,\n  \"fields\": [\n    {\n      \"column\": \"flags\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"BCZ\",\n          \"BNQ\",\n          \"BCQ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 493,\n        \"samples\": [\n          \"can you help me camceling the purchase I made?\",\n          \"whag do i need to do to cancel order {{Order Number}}\",\n          \"I bought some product, I want to cancel order {{Order Number}}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ORDER\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"cancel_order\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 998,\n        \"samples\": [\n          \"I understand the financial constraints you are facing and the need to cancel purchase {{Order Number}}. Our goal is to assist you in the best way possible. To proceed with the cancellation, please follow these steps:\\n\\n1. Sign in to Your Account: Access our {{Online Company Portal Info}} by signing in with your credentials.\\n\\n2. Navigate to Your Orders: Once you are signed in, locate the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section.\\n\\n3. Find the Relevant Purchase: Look for the purchase associated with the order number {{Order Number}} and click on it for more details.\\n\\n4. Initiate Cancellation: You will see an option labeled '{{Online Order Interaction}}.' Please select this option to begin the cancellation process.\\n\\n5. Complete the Cancellation: Follow any further instructions or prompts to complete the cancellation successfully.\\n\\nIf you encounter any issues or have any questions during the process, please don't hesitate to contact our dedicated customer support team during {{Customer Support Hours}}. You can reach us at {{Customer Support Phone Number}} or use the Live Chat feature on our website at {{Website URL}}. We are committed to your satisfaction and will do our best to assist you.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_entries = []\n",
        "for i in range(0, len(df_q_a_MM)):\n",
        "  entry = {\n",
        "      'question': f\"### Below is an instruction that describes a task. Write a response that appropriately completes the request. \\nQuestion:\\n{df_q_a_MM.iloc[i]['instruction']}\\n\\n### Answer:\",\n",
        "      'answer': df_q_a_MM.iloc[i]['response']\n",
        "  }\n",
        "  list_of_entries.append(entry)"
      ],
      "metadata": {
        "id": "3U7jXaBRnaQZ"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_entries[0]"
      ],
      "metadata": {
        "id": "xHIeDyqXnaSv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f9115d9-c552-4a40-801f-6b09f22f82f9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': '### Below is an instruction that describes a task. Write a response that appropriately completes the request. \\nQuestion:\\nquestion about cancelling order {{Order Number}}\\n\\n### Answer:',\n",
              " 'answer': \"I've understood you have a question regarding canceling order {{Order Number}}, and I'm here to provide you with the information you need. Please go ahead and ask your question, and I'll do my best to assist you.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now tokenize this."
      ],
      "metadata": {
        "id": "KJHFdksGo3Dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = list_of_entries[0][\"question\"] + list_of_entries[0][\"answer\"]\n",
        "tokenized_inputs = tokenizer(\n",
        "    text,\n",
        "    return_tensors=\"np\",\n",
        "    padding=True\n",
        ")\n",
        "print(tokenized_inputs[\"input_ids\"])"
      ],
      "metadata": {
        "id": "gLu_BYccnaXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b97485ac-6ae7-46a6-baa6-c1db6c466212"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4118 23195   310   271  9775   326  8631   247  4836    15 19566   247\n",
            "   2380   326 20420 29141   253  2748    15   209   187 23433    27   187\n",
            "  19751   670   476    68  3485  1340 12033 13921 11057   599   187   187\n",
            "   4118 37741    27    42  1849  7192   368   452   247  1953  5001 14002\n",
            "    272  1340 12033 13921 11057  8503   285   309  1353  1060   281  2085\n",
            "    368   342   253  1491   368   878    15  7764   564  6386   285  1642\n",
            "    634  1953    13   285   309  1833   513   619  1682   281 10073   368\n",
            "     15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's perform tokenization on the list of entries that we have prepared."
      ],
      "metadata": {
        "id": "x28XUNQkAo-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "finetuning_dataset = Dataset.from_pandas(pd.DataFrame(list_of_entries))"
      ],
      "metadata": {
        "id": "yY9PdXU4Cu95"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetuning_dataset['question'][1]"
      ],
      "metadata": {
        "id": "EzhHEVENDX4u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "bd09695f-d139-45e2-c95a-182a24df47b1"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'### Below is an instruction that describes a task. Write a response that appropriately completes the request. \\nQuestion:\\ni have a question about cancelling oorder {{Order Number}}\\n\\n### Answer:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuning_dataset[\"answer\"][1]"
      ],
      "metadata": {
        "id": "x8Hy-f1zy5bm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "928ce6cb-a02a-4250-fdc2-7c01f5c4d7a5"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I've been informed that you have a question about canceling order {{Order Number}}. I'm here to assist you! Please go ahead and let me know what specific question you have, and I'll provide you with all the information and guidance you need. Your satisfaction is my top priority.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuning_dataset"
      ],
      "metadata": {
        "id": "COGEFXMOhMwk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eab28c3-34da-48a4-871b-10f43d36649b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question', 'answer'],\n",
              "    num_rows: 998\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's write a function that can do tokenization for any entry."
      ],
      "metadata": {
        "id": "TgM6cSGFAc_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "    # Combine question and answer\n",
        "    text = example['question'] + \" \" + example['answer']\n",
        "\n",
        "    # Tokenize the combined text\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=2048,\n",
        "        return_tensors=\"np\"\n",
        "    )\n",
        "\n",
        "    # Remove the batch dimension added by tokenizer\n",
        "    tokenized_inputs = {k: v.squeeze(0) for k, v in tokenized_inputs.items()}\n",
        "\n",
        "    # Combine the original example with the tokenized inputs\n",
        "    return {**example, **tokenized_inputs}\n",
        "\n",
        "# Apply the tokenization to the dataset\n",
        "tokenized_dataset = finetuning_dataset.map(tokenize_function)\n",
        "\n",
        "print(tokenized_dataset)"
      ],
      "metadata": {
        "id": "bWQHkcm6heSg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "cdae945856b444d4800bccc31199e2b7",
            "21e1c4dcc7b940e78a0bea2208d17bdf",
            "b654f5fb85b64830abb1db38965325f3",
            "650d35f7494f48b5a697135f65ce4d39",
            "fd1d9db94ebe4d52ac67a01944e3d5b5",
            "950b91c9f37c4496972674202fe44b4e",
            "f7ba6a2e3573487b91dbd3503727dbc4",
            "6fae6392ca7042d4ae8a66f6b1746a25",
            "c8908b8b34ee49afb45e397be7488116",
            "a20774d93b084842824a8739638d03ea",
            "756340a91bf94fc99de71c16ce03d184"
          ]
        },
        "outputId": "14caced0-4b38-4ba5-9c58-93935f56b233"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/998 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdae945856b444d4800bccc31199e2b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['question', 'answer', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 998\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, the trainer that we will use from the `transformers` library looks for a column named `labels`. Therefore, we will copy the `input_ids` column to create a new column called `labels`."
      ],
      "metadata": {
        "id": "5OSL4rKIEM67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = tokenized_dataset.add_column(\"labels\", tokenized_dataset[\"input_ids\"])"
      ],
      "metadata": {
        "id": "d1APiUCDrwYK"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we need to perform train-test split on this data set."
      ],
      "metadata": {
        "id": "UtJ59ngrAu_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/test split"
      ],
      "metadata": {
        "id": "AicjUpxGr2Gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, shuffle=True, seed=123)\n",
        "print(split_dataset)"
      ],
      "metadata": {
        "id": "2s-U6Hxzo_Jt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52aa6178-0f62-4510-cfd1-f883dff47444"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 898\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 100\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = split_dataset[\"train\"]\n",
        "test_dataset = split_dataset[\"test\"]\n",
        "\n",
        "print(train_dataset)\n",
        "print(test_dataset)\n"
      ],
      "metadata": {
        "id": "YgtxSdH4o_MC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b90d6e54-0f0c-4f22-e47b-1487506123be"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 898\n",
            "})\n",
            "Dataset({\n",
            "    features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 100\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our data is ready, we can move on to training the model."
      ],
      "metadata": {
        "id": "NRqeHgDYAybE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and inference\n",
        "\n",
        "Let's now train the model\n",
        "\n",
        "## Training the model\n"
      ],
      "metadata": {
        "id": "GsvycLQ7sBle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global_config = None"
      ],
      "metadata": {
        "id": "3gbNUJpao_OY"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"EleutherAI/pythia-70m\""
      ],
      "metadata": {
        "id": "9BqxDUUbo_Qg"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "uTQLtEVosKZ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "302d138c-29c0-4113-a16b-c74ba54f5b9c"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
        "  # Define the function 'inference' which takes a piece of text, a model, a tokenizer,\n",
        "  # and optional arguments for the maximum number of input and output tokens.\n",
        "\n",
        "  # Tokenize the input text.\n",
        "  input_ids = tokenizer.encode(\n",
        "          text,\n",
        "          return_tensors=\"pt\",  # Return the result as PyTorch tensors.\n",
        "          truncation=True,  # Truncate the text to fit the max input length.\n",
        "          max_length=max_input_tokens  # Set the maximum token length for the input text.\n",
        "  )\n",
        "\n",
        "  # Create an attention mask which is 1 for real tokens and 0 for padding tokens.\n",
        "  attention_mask = (input_ids != tokenizer.pad_token_id).int()\n",
        "\n",
        "  # Assign the model's device to a variable. This ensures that tensor operations\n",
        "  # are performed on the same device where the model is loaded (CPU/GPU).\n",
        "  device = model.device\n",
        "\n",
        "  # Generate tokens using the model, passing in the processed inputs.\n",
        "  generated_tokens_with_prompt = model.generate(\n",
        "    input_ids=input_ids.to(device),  # Move input tokens to the same device as the model.\n",
        "    max_length=max_output_tokens,  # Set the maximum token length for the output text.\n",
        "    attention_mask=attention_mask,  # Provide the attention mask for the model to ignore padding.\n",
        "    pad_token_id=tokenizer.eos_token_id  # Specify the end-of-sequence token ID for padding if needed.\n",
        "  )\n",
        "\n",
        "  # Decode the generated tokens back into text, ignoring special tokens like padding or end-of-sequence.\n",
        "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
        "\n",
        "  # Remove the initial prompt from the generated text to obtain only the model's output.\n",
        "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
        "\n",
        "  # Return the final generated text, which is the answer from the model without the prompt.\n",
        "  return generated_text_answer"
      ],
      "metadata": {
        "id": "nm1zj9LHsKee"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = test_dataset[0]['question']\n",
        "print(\"Question input (test):\", test_text)\n",
        "print(f\"Correct answer from the dataset: {test_dataset[0]['answer']}\")\n",
        "print(\"Model's answer: \")\n",
        "print(inference(test_text, base_model, tokenizer))"
      ],
      "metadata": {
        "id": "sYvAsg6ZsKg1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e89a856-b168-41f0-d428-2599842195ea"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question input (test): ### Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
            "Question:\n",
            "i need assistance with canceling purchase {{Order Number}}\n",
            "\n",
            "### Answer:\n",
            "Correct answer from the dataset: I've grasped that you're seeking assistance with canceling purchase {{Order Number}}, and I'm here to guide you through the process. Cancelling a purchase is important, and we want to ensure a smooth experience for you. Here's what you need to do:\n",
            "\n",
            "1. Access Your Account: Start by logging in to our {{Online Company Portal Info}}.\n",
            "2. Locate Your Purchase: Once logged in, navigate to the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section.\n",
            "3. Identify the Purchase: Look for the purchase associated with the order number {{Order Number}}. Click on it for more details.\n",
            "4. Initiate the Cancellation: You'll find the option to '{{Online Order Interaction}}' linked with your purchase. Please select that.\n",
            "5. Complete the Process: Our system may prompt you for additional information or feedback to finalize the cancellation.\n",
            "\n",
            "If you encounter any difficulties or have any questions during the process, our dedicated team is available during {{Customer Support Hours}} at {{Customer Support Phone Number}} or through the Live Chat feature on our website at {{Website URL}}. We value your satisfaction and are committed to providing you the assistance you need.\n",
            "Model's answer: \n",
            "\n",
            "i need assistance with canceling purchase {{Order Number}}\n",
            "\n",
            "### Answer:\n",
            "i need assistance with canceling purchase {{Order Number}}\n",
            "\n",
            "### Answer:\n",
            "i need assistance with canceling purchase {{Order Number}}\n",
            "\n",
            "### Answer:\n",
            "i need assistance with canceling purchase {{\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 50"
      ],
      "metadata": {
        "id": "yvnM3qLv_kKi"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model_name = f\"q_a_{max_steps}_steps_MM\"\n",
        "output_dir = trained_model_name"
      ],
      "metadata": {
        "id": "icMAuLYptbl8"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the TrainingArguments with various hyperparameters and settings for training.\n",
        "training_args = TrainingArguments(\n",
        "\n",
        "  # Specify the learning rate for the optimizer.\n",
        "  learning_rate=1.0e-5,\n",
        "\n",
        "  # Define the number of epochs for training (complete passes over the dataset).\n",
        "  num_train_epochs=5,\n",
        "\n",
        "  # Indicate the maximum number of training steps (batches of data) to perform.\n",
        "  # If set to a value other than -1, it will override num_train_epochs.\n",
        "  # max_steps=max_steps,\n",
        "\n",
        "  # Set the size of each training batch that is processed per device (e.g., per GPU).\n",
        "  per_device_train_batch_size=1,\n",
        "\n",
        "  # Designate the directory where the model checkpoints will be saved during training.\n",
        "  output_dir=output_dir,\n",
        "\n",
        "  # If set to True, the content of the output directory will be overwritten.\n",
        "  overwrite_output_dir=False,\n",
        "\n",
        "  # Determines how often the evaluation phase is run during training (after this many steps).\n",
        "  eval_steps=120,\n",
        "\n",
        "  # Sets how often to save a model checkpoint (after this many steps).\n",
        "  save_steps=120,\n",
        "\n",
        "  # Number of steps to perform learning rate warmup, which can improve training stability.\n",
        "  warmup_steps=1,\n",
        "\n",
        "  # Set the size of each evaluation batch that is processed per device.\n",
        "  per_device_eval_batch_size=1,\n",
        "\n",
        "  # Determines the evaluation strategy to use during training.\n",
        "  # \"Steps\" means to evaluate after a certain number of training steps.\n",
        "  evaluation_strategy=\"steps\",\n",
        "\n",
        "  # Indicates the logging strategy to use, which determines how often to log metrics.\n",
        "  # \"Steps\" means to log after a certain number of training steps.\n",
        "  logging_strategy=\"steps\",\n",
        "\n",
        "  # Configures how often to log training metrics (after this many steps).\n",
        "  logging_steps=1,\n",
        "\n",
        "  # Specifies the optimizer to use during training. 'adafactor' is a memory-efficient optimizer.\n",
        "  optim=\"adafactor\",\n",
        "\n",
        "  # Number of steps for which gradients are accumulated before performing a backpropagation update.\n",
        "  gradient_accumulation_steps=4,\n",
        "\n",
        "  # Enables or disables gradient checkpointing, which can save memory at the cost of slower backward passes.\n",
        "  gradient_checkpointing=False,\n",
        "\n",
        "  # If set to True, the model with the best evaluation metric will be loaded at the end of training.\n",
        "  load_best_model_at_end=True,\n",
        "\n",
        "  # Limits the total number of model checkpoints to save, to manage storage space.\n",
        "  save_total_limit=1,\n",
        "\n",
        "  # Indicates which metric to use for identifying the 'best' model during training.\n",
        "  metric_for_best_model=\"eval_loss\",\n",
        "\n",
        "  # When set to False, a lower metric is considered better for 'metric_for_best_model'.\n",
        "  greater_is_better=False\n",
        ")"
      ],
      "metadata": {
        "id": "mqMi982itboR"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=base_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "#training_output = trainer.train()\n",
        "training_output = trainer.train()\n",
        "path_1='/content/drive/My Drive/genAI/fine tuning/'\n",
        "\n",
        "save_dir =path_1 + f'{output_dir}/final'\n",
        "\n",
        "#save_dir = f'{output_dir}/final'\n",
        "\n",
        "trainer.save_model(save_dir)\n",
        "print(\"Saved model to:\", save_dir)\n",
        "\n",
        "finetuned_slightly_model = AutoModelForCausalLM.from_pretrained(save_dir, local_files_only=True)\n",
        "finetuned_slightly_model.to(torch.device(\"cpu\"))"
      ],
      "metadata": {
        "id": "ux2mJTaWulUY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "outputId": "805d3ddd-3ce2-4c6a-b94b-988160fca4f6"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1120' max='1120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1120/1120 23:43, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.095900</td>\n",
              "      <td>0.093369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.081000</td>\n",
              "      <td>0.081774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.073300</td>\n",
              "      <td>0.077139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.062100</td>\n",
              "      <td>0.074401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.069100</td>\n",
              "      <td>0.071782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.052600</td>\n",
              "      <td>0.071566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.067500</td>\n",
              "      <td>0.069703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.050900</td>\n",
              "      <td>0.069569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.060400</td>\n",
              "      <td>0.069074</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2159: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(best_model_path, map_location=\"cpu\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to: /content/drive/My Drive/genAI/fine tuning/q_a_50_steps_MM/final\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTNeoXForCausalLM(\n",
              "  (gpt_neox): GPTNeoXModel(\n",
              "    (embed_in): Embedding(50304, 512)\n",
              "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the model is trained, we can perform inference on the model."
      ],
      "metadata": {
        "id": "QhUHlwhyBidg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference on finetuned model"
      ],
      "metadata": {
        "id": "lfxRyKd4uZqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output from the foundation model."
      ],
      "metadata": {
        "id": "iXmCeaxiyQtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_question = test_dataset[0]['question']\n",
        "print(\"Question input (test):\", test_question)\n",
        "\n",
        "print(\"Finetuned slightly model's answer: \")\n",
        "print(inference(test_question, finetuned_slightly_model, tokenizer))"
      ],
      "metadata": {
        "id": "KpC3GM9gtbzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e0cfb8-18b0-4326-ee50-c72000a8d8a8"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question input (test): ### Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
            "Question:\n",
            "i need assistance with canceling purchase {{Order Number}}\n",
            "\n",
            "### Answer:\n",
            "Finetuned slightly model's answer: \n",
            " I've understood, you need assistance with canceling your purchase with the order number {{Order Number}}. I apologize for any inconvenience this may have caused you. To cancel your purchase, please follow these steps:\n",
            "\n",
            "1. Sign in to your {{Online Company Portal Info}} using your credentials.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_answer = test_dataset[0]['answer']\n",
        "print(\"Target answer output (test):\", test_answer)"
      ],
      "metadata": {
        "id": "7LcqIKnqtb1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b97ff77b-f1fc-4ed0-99e7-5ea92abefce7"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target answer output (test): I've grasped that you're seeking assistance with canceling purchase {{Order Number}}, and I'm here to guide you through the process. Cancelling a purchase is important, and we want to ensure a smooth experience for you. Here's what you need to do:\n",
            "\n",
            "1. Access Your Account: Start by logging in to our {{Online Company Portal Info}}.\n",
            "2. Locate Your Purchase: Once logged in, navigate to the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section.\n",
            "3. Identify the Purchase: Look for the purchase associated with the order number {{Order Number}}. Click on it for more details.\n",
            "4. Initiate the Cancellation: You'll find the option to '{{Online Order Interaction}}' linked with your purchase. Please select that.\n",
            "5. Complete the Process: Our system may prompt you for additional information or feedback to finalize the cancellation.\n",
            "\n",
            "If you encounter any difficulties or have any questions during the process, our dedicated team is available during {{Customer Support Hours}} at {{Customer Support Phone Number}} or through the Live Chat feature on our website at {{Website URL}}. We value your satisfaction and are committed to providing you the assistance you need.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next steps:\n",
        "1. Train the model using the whole data set\n",
        "2. Tune the number of epochs needed to minimize the validation error\n",
        "3. Increase the number of tokens in the model.\n",
        "4. Use a larger model for fine-tuning\n",
        "5. Use parameter efficient fine-tuning techniques like LoRA and qLoRA"
      ],
      "metadata": {
        "id": "4EASt1WIAC2K"
      }
    }
  ]
}